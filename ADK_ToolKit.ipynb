{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ntrajic/AgenticRoomReservation/blob/main/ADK_ToolKit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🚀 The Ultimate ADK Toolkit: A Developer's Guide to Tool Integration 🚀\n",
        "\n",
        "Welcome, Agent Architect! This notebook is your definitive guide to giving AI agents superpowers through **tool integration**. An agent's true power isn't just its language model; it's its ability to connect to and interact with the outside world. We will explore the entire spectrum of tool integration patterns available in the Google Agent Development Kit (ADK).\n",
        "\n",
        "By the end of this adventure, you will master how to:\n",
        "\n",
        "- ✅ **Use Built-in & Custom Function Tools**: The foundational patterns for giving an agent new skills.\n",
        "- ✅ **Generate Tools from Specifications**: Automatically create toolsets from **OpenAPI** specs and connect to enterprise APIs in **Google Cloud API Hub**.\n",
        "- ✅ **Connect to Live Tool Servers**: Use **MCP** to have your agent dynamically discover tools hosted anywhere on the web.\n",
        "- ✅ **Integrate with Other Frameworks**: Seamlessly use tools from the **LangChain** ecosystem directly within your ADK agent.\n",
        "- ✅ **Share State Between Tools**: Use `ToolContext` to enable complex, multi-step workflows where tools can pass information to each other.\n",
        "- ✅ **Build Multi-Agent Systems**: Create sophisticated systems where a primary \"orchestrator\" agent can delegate tasks to specialist agents.\n",
        "\n",
        "Let's dive into the toolkit!"
      ],
      "metadata": {
        "id": "intro"
      },
      "id": "intro"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Author\n",
        "\n",
        "Hi, I'm Qingyue (Annie) Wang, a Developer Advocate and AI Engineer at **Google**. I'm passionate about helping developers build amazing things with AI and cloud technologies.\n",
        "\n",
        "If you have questions about this notebook, feel free to reach out on [LinkedIn](https://www.linkedin.com/in/qingyuewang/) or [X (formerly Twitter)](https://twitter.com/qingyuewang).\n",
        "\n",
        "```\n",
        " (\\__/)\n",
        " (•ㅅ•)\n",
        " /づ  📚      Enjoy learning about AI Agents!\n",
        "```"
      ],
      "metadata": {
        "id": "author"
      },
      "id": "author"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 🎁 🛑 Important Prerequisite: Setup Your Environment! 🛑 🎁\n",
        "-----------------------------------------------------------------------------\n",
        "\n",
        "You will need a **Google AI API Key** to run this notebook.\n",
        "\n",
        "👉 **Get Your Key HERE**: [https://codelabs.developers.google.com/onramp/instructions#1](https://codelabs.developers.google.com/onramp/instructions#1)\n",
        "\n",
        "*Note: The LangChain integration in Part 4 requires an additional API key from a service like Tavily, which has a free tier.*\n",
        "\n",
        "-----------------------------------------------------------------------------\n",
        "```\n",
        " ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️\n",
        "   /\\_/\\     /\\_/\\     /\\_/\\      /\\_/\\      /\\_/\\\n",
        "  ( ^_^ )   ( -.- )   ( >_< )   ( =^.^= )   ( o_o )\n",
        "```"
      ],
      "metadata": {
        "id": "prereq"
      },
      "id": "prereq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Part 0: Setup & Authentication 🔑\n",
        "\n",
        "Let's install all necessary libraries and configure your API key. This single setup will prepare you for every example in the notebook."
      ],
      "metadata": {
        "id": "setup_intro"
      },
      "id": "setup_intro"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "install_code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db272d97-2a27-43df-a171-67238af20901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.5/158.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m128.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m133.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.1/218.1 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.7/335.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.6/441.6 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.9/367.9 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.5/229.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.3/394.3 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.8/103.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.5/585.5 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m✅ All libraries are installed and ready to go!\n"
          ]
        }
      ],
      "source": [
        "# Install all the packages we'll need for this entire tutorial\n",
        "# This includes the ADK, Google's AI library, and libraries for specific integrations\n",
        "!pip install google-adk google-generativeai mcp requests nest-asyncio langchain-community tavily-python wikipedia -q\n",
        "\n",
        "# --- Import all necessary libraries ---\n",
        "import asyncio\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import traceback\n",
        "from getpass import getpass\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# ADK and Tool imports\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.tools import google_search, ToolContext\n",
        "from google.adk.tools.agent_tool import AgentTool\n",
        "from google.adk.tools.openapi_tool import OpenAPIToolset\n",
        "from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\n",
        "from google.adk.tools.mcp_tool.mcp_session_manager import SseServerParams\n",
        "from google.adk.tools.langchain_tool import LangchainTool\n",
        "# Note: APIHubToolset is shown for conceptual purposes\n",
        "# from google.adk.tools.apihub_tool import APIHubToolset\n",
        "\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService, Session\n",
        "\n",
        "# Google AI imports\n",
        "import google.generativeai as genai\n",
        "from google.genai.types import Content, Part\n",
        "\n",
        "# LangChain imports for Part 4\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "\n",
        "# A helper to run async ADK code in Colab/Jupyter\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "print(\"✅ All libraries are installed and ready to go!\")"
      ],
      "id": "install_code"
    },
    {
      "cell_type": "code",
      "source": [
        "google_api_key = getpass('Enter your Google API Key: ')\n",
        "genai.configure(api_key=google_api_key)\n",
        "os.environ['GOOGLE_API_KEY'] = google_api_key\n",
        "print(\"✅ Google API Key configured.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUbnRdaSktt4",
        "outputId": "3b334d38-855e-4e6e-d074-99430b7ce4aa"
      },
      "id": "EUbnRdaSktt4",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Google API Key: ··········\n",
            "✅ Google API Key configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A Helper Function to Run Our Agents\n",
        "To keep our code clean, we'll define a single helper function to manage running our agents."
      ],
      "metadata": {
        "id": "helper_intro"
      },
      "id": "helper_intro"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "helper_code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb98db3c-c9f7-4c2c-ffd0-3d26dcb452f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Agent query helper function defined.\n"
          ]
        }
      ],
      "source": [
        "# Initialize a session service to manage conversations\n",
        "session_service = InMemorySessionService()\n",
        "my_user_id = \"adk_toolkit_user\"\n",
        "\n",
        "async def run_agent_query(agent: Agent, query: str):\n",
        "    \"\"\"A reusable function to run a query against any agent.\"\"\"\n",
        "    session = await session_service.create_session(app_name=agent.name, user_id=my_user_id)\n",
        "    print(f\"\\n🚀 Running query for agent: '{agent.name}'...\")\n",
        "\n",
        "    runner = Runner(agent=agent, session_service=session_service, app_name=agent.name)\n",
        "    final_response = \"\"\n",
        "    try:\n",
        "        async for event in runner.run_async(\n",
        "            user_id=my_user_id,\n",
        "            session_id=session.id,\n",
        "            new_message=Content(parts=[Part(text=query)], role=\"user\")\n",
        "        ):\n",
        "            # To see the agent's full thought process, uncomment the line below\n",
        "            # print(f\"EVENT: {event}\")\n",
        "            if event.is_final_response() and event.content.parts:\n",
        "                final_response += event.content.parts[0].text\n",
        "    except Exception as e:\n",
        "        final_response = f\"An error occurred: {e}\"\n",
        "        print(\"\\n🔍 Full traceback:\")\n",
        "        print(traceback.format_exc())\n",
        "\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"✅ Final Response:\")\n",
        "    display(Markdown(final_response))\n",
        "    print(\"-\"*50 + \"\\n\")\n",
        "    return final_response\n",
        "\n",
        "print(\"✅ Agent query helper function defined.\")"
      ],
      "id": "helper_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Part 1: The Basics - Direct Tooling\n",
        "\n",
        "These are the most fundamental ways to give an agent new skills."
      ],
      "metadata": {
        "id": "part1_intro"
      },
      "id": "part1_intro"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Built-in Tools\n",
        "The ADK comes with pre-packaged tools. `Google Search` is the perfect example, giving your agent immediate access to real-time information."
      ],
      "metadata": {
        "id": "builtin_intro"
      },
      "id": "builtin_intro"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "builtin_code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8247ea2-1ee3-4860-a6f3-cb449b130ba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Running query for agent: 'search_agent'...\n",
            "\n",
            "--------------------------------------------------\n",
            "✅ Final Response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The Artemis program, led by NASA, is an ongoing initiative focused on returning humans to the Moon and establishing a sustainable lunar presence as a step towards human missions to Mars. The program's first uncrewed test flight, Artemis I, was successfully completed in November 2022.\n\nHere's the latest on upcoming missions:\n\n**Artemis II**\n*   **Target Launch Date:** Artemis II is currently scheduled for launch no earlier than April 2026, though NASA is looking for ways to enable an earlier launch, potentially as soon as February 2026. This mission will be the first crewed test flight of the Space Launch System (SLS) rocket and the Orion spacecraft, carrying four astronauts on a free-return trajectory around the Moon.\n*   **Recent Developments:**\n    *   In March 2025, NASA announced that the target launch date for Artemis II had been moved up by two months to February 2026.\n    *   As of May 2025, the SLS for Artemis II is fully stacked on Mobile Launcher 1, awaiting the Orion spacecraft and its ascent abort motor fairing.\n    *   Lockheed Martin handed over the Orion spacecraft for Artemis II to NASA Exploration Ground Systems on May 1, 2025, after final assembly.\n    *   The Orion spacecraft was moved to the Multi-Payload Processing Facility (MPPF) for hypergolic propellant and other consumables loading.\n    *   The Artemis II crew conducted their first series of trainings and simulations in May 2024.\n    *   In September 2024, NASA announced that five CubeSats from international partners would fly aboard the Artemis II mission.\n    *   A NASA Office of Inspector General (OIG) report in May 2024 indicated the mission was still on track, provided corrective actions on the Orion heat shield were made. The heat shield issues on the Orion capsule from Artemis I and valve problems in the spacecraft's life support system had previously caused delays for both Artemis II and Artemis III.\n\n**Artemis III**\n*   **Target Launch Date:** Artemis III is now expected to launch no earlier than mid-2027. This mission aims to be the first American crewed lunar landing since Apollo 17 in 1972, with the goal of landing the first woman and first person of color on the lunar surface.\n*   **Recent Developments:**\n    *   NASA identified an updated set of nine potential landing regions near the lunar South Pole for the Artemis III mission in October and November 2024. These regions are being further investigated for scientific value, mission availability, terrain suitability, communication capabilities with Earth, and lighting conditions.\n    *   In February 2024, NASA completed full qualification testing of the docking systems on Starship Human Landing System (HLS), which is crucial for Artemis III.\n    *   The bulk of the manufacturing for the core stage of the SLS for Artemis III was completed in February 2024.\n    *   In April 2024, NASA announced the successful completion of Starship's first internal propellant transfer demonstration, a key capability for the mission.\n    *   The European Service Module for Artemis III was reported to be on track for handover to NASA in summer 2024 and was completed and delivered in September 2024.\n    *   The first integrated test for the mission, including next-generation spacesuits by Axiom Space and the Starship HLS airlock module, was conducted in June 2024.\n    *   As of April 22, 2025, the liquid hydrogen tank for the Artemis III SLS rocket was moved into the factory's final assembly area.\n\n**Future Artemis Missions & Other News**\n*   Artemis IV is planned for late 2028 and will involve docking with the Lunar Gateway.\n*   Artemis V is planned for early 2030 and will deliver additional elements to the Lunar Gateway and be the third lunar landing, utilizing a Blue Moon lunar lander and a Lunar Terrain Vehicle (LTV).\n*   Artemis VI is planned for early 2031 and will integrate the Crew and Science Airlock with the Lunar Gateway.\n*   After Artemis VI, NASA plans yearly landings on the Moon.\n*   In June 2025, a solid rocket engine for NASA's Space Launch System rocket experienced an anomaly during a static fire test.\n*   Norway became the 55th nation to sign the NASA Artemis Accords for peaceful space exploration.\n*   The proposed NASA budget for Fiscal Year 2026 aims to end the SLS and Orion programs after the Artemis III lunar landing, though this is a proposal and faces uncertainties."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Artemis program, led by NASA, is an ongoing initiative focused on returning humans to the Moon and establishing a sustainable lunar presence as a step towards human missions to Mars. The program's first uncrewed test flight, Artemis I, was successfully completed in November 2022.\\n\\nHere's the latest on upcoming missions:\\n\\n**Artemis II**\\n*   **Target Launch Date:** Artemis II is currently scheduled for launch no earlier than April 2026, though NASA is looking for ways to enable an earlier launch, potentially as soon as February 2026. This mission will be the first crewed test flight of the Space Launch System (SLS) rocket and the Orion spacecraft, carrying four astronauts on a free-return trajectory around the Moon.\\n*   **Recent Developments:**\\n    *   In March 2025, NASA announced that the target launch date for Artemis II had been moved up by two months to February 2026.\\n    *   As of May 2025, the SLS for Artemis II is fully stacked on Mobile Launcher 1, awaiting the Orion spacecraft and its ascent abort motor fairing.\\n    *   Lockheed Martin handed over the Orion spacecraft for Artemis II to NASA Exploration Ground Systems on May 1, 2025, after final assembly.\\n    *   The Orion spacecraft was moved to the Multi-Payload Processing Facility (MPPF) for hypergolic propellant and other consumables loading.\\n    *   The Artemis II crew conducted their first series of trainings and simulations in May 2024.\\n    *   In September 2024, NASA announced that five CubeSats from international partners would fly aboard the Artemis II mission.\\n    *   A NASA Office of Inspector General (OIG) report in May 2024 indicated the mission was still on track, provided corrective actions on the Orion heat shield were made. The heat shield issues on the Orion capsule from Artemis I and valve problems in the spacecraft's life support system had previously caused delays for both Artemis II and Artemis III.\\n\\n**Artemis III**\\n*   **Target Launch Date:** Artemis III is now expected to launch no earlier than mid-2027. This mission aims to be the first American crewed lunar landing since Apollo 17 in 1972, with the goal of landing the first woman and first person of color on the lunar surface.\\n*   **Recent Developments:**\\n    *   NASA identified an updated set of nine potential landing regions near the lunar South Pole for the Artemis III mission in October and November 2024. These regions are being further investigated for scientific value, mission availability, terrain suitability, communication capabilities with Earth, and lighting conditions.\\n    *   In February 2024, NASA completed full qualification testing of the docking systems on Starship Human Landing System (HLS), which is crucial for Artemis III.\\n    *   The bulk of the manufacturing for the core stage of the SLS for Artemis III was completed in February 2024.\\n    *   In April 2024, NASA announced the successful completion of Starship's first internal propellant transfer demonstration, a key capability for the mission.\\n    *   The European Service Module for Artemis III was reported to be on track for handover to NASA in summer 2024 and was completed and delivered in September 2024.\\n    *   The first integrated test for the mission, including next-generation spacesuits by Axiom Space and the Starship HLS airlock module, was conducted in June 2024.\\n    *   As of April 22, 2025, the liquid hydrogen tank for the Artemis III SLS rocket was moved into the factory's final assembly area.\\n\\n**Future Artemis Missions & Other News**\\n*   Artemis IV is planned for late 2028 and will involve docking with the Lunar Gateway.\\n*   Artemis V is planned for early 2030 and will deliver additional elements to the Lunar Gateway and be the third lunar landing, utilizing a Blue Moon lunar lander and a Lunar Terrain Vehicle (LTV).\\n*   Artemis VI is planned for early 2031 and will integrate the Crew and Science Airlock with the Lunar Gateway.\\n*   After Artemis VI, NASA plans yearly landings on the Moon.\\n*   In June 2025, a solid rocket engine for NASA's Space Launch System rocket experienced an anomaly during a static fire test.\\n*   Norway became the 55th nation to sign the NASA Artemis Accords for peaceful space exploration.\\n*   The proposed NASA budget for Fiscal Year 2026 aims to end the SLS and Orion programs after the Artemis III lunar landing, though this is a proposal and faces uncertainties.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Define an agent and give it the built-in Google Search tool\n",
        "search_agent = Agent(\n",
        "    name=\"search_agent\",\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    instruction=\"You are a helpful search assistant. Answer the user's question using Google Search.\",\n",
        "    tools=[google_search]\n",
        ")\n",
        "\n",
        "# Run the agent\n",
        "await run_agent_query(search_agent, \"What is the latest news about the Artemis program?\")"
      ],
      "id": "builtin_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Custom Function Tools\n",
        "This is the most common pattern: wrapping your own Python function into a tool. The function's **docstring** is crucial, as it tells the LLM what the tool does and when to use it. Here, we'll create a tool to fetch live weather data from the public U.S. National Weather Service API."
      ],
      "metadata": {
        "id": "custom_function_intro"
      },
      "id": "custom_function_intro"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "custom_function_code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "2a9e0c51-ad0a-40cd-c079-2309c34abc04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌦️ Agent 'weather_aware_planner' is created and can now call a live weather API!\n",
            "\n",
            "🚀 Running query for agent: 'weather_aware_planner'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🛠️ TOOL CALLED: get_live_weather_forecast(location='Lake Tahoe')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "✅ Final Response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The weather near Lake Tahoe tomorrow will be sunny with a high near 75°F. There will be a west wind ranging from 5 to 15 mph. It sounds like perfect weather for a hike! Enjoy your time."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The weather near Lake Tahoe tomorrow will be sunny with a high near 75°F. There will be a west wind ranging from 5 to 15 mph. It sounds like perfect weather for a hike! Enjoy your time.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# --- Tool Definition: A function that calls a live public API ---\n",
        "# A simple lookup to avoid needing a separate geocoding API for this example\n",
        "LOCATION_COORDINATES = {\n",
        "    \"sunnyvale\": \"37.3688,-122.0363\",\n",
        "    \"san francisco\": \"37.7749,-122.4194\",\n",
        "    \"lake tahoe\": \"39.0968,-120.0324\"\n",
        "}\n",
        "\n",
        "def get_live_weather_forecast(location: str) -> dict:\n",
        "    \"\"\"Gets the current, real-time weather forecast for a specified location in the US.\n",
        "\n",
        "    Args:\n",
        "        location: The city name, e.g., \"San Francisco\".\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the temperature and a detailed forecast.\n",
        "    \"\"\"\n",
        "    print(f\"\\n🛠️ TOOL CALLED: get_live_weather_forecast(location='{location}')\\n\")\n",
        "\n",
        "    # Find coordinates for the location\n",
        "    normalized_location = location.lower()\n",
        "    coords_str = None\n",
        "    for key, val in LOCATION_COORDINATES.items():\n",
        "        if key in normalized_location:\n",
        "            coords_str = val\n",
        "            break\n",
        "    if not coords_str:\n",
        "        return {\"status\": \"error\", \"message\": f\"I don't have coordinates for {location}.\"}\n",
        "\n",
        "    try:\n",
        "        # NWS API requires 2 steps: 1. Get the forecast URL from the coordinates.\n",
        "        points_url = f\"https://api.weather.gov/points/{coords_str}\"\n",
        "        headers = {\"User-Agent\": \"ADK Example Notebook\"}\n",
        "        points_response = requests.get(points_url, headers=headers)\n",
        "        points_response.raise_for_status() # Raise an exception for bad status codes\n",
        "        forecast_url = points_response.json()['properties']['forecast']\n",
        "\n",
        "        # 2. Get the actual forecast from the URL.\n",
        "        forecast_response = requests.get(forecast_url, headers=headers)\n",
        "        forecast_response.raise_for_status()\n",
        "\n",
        "        # Extract the relevant forecast details\n",
        "        current_period = forecast_response.json()['properties']['periods'][0]\n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"temperature\": f\"{current_period['temperature']}°{current_period['temperatureUnit']}\",\n",
        "            \"forecast\": current_period['detailedForecast']\n",
        "        }\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return {\"status\": \"error\", \"message\": f\"API request failed: {e}\"}\n",
        "\n",
        "# --- Agent Definition: An agent that USES the new tool ---\n",
        "weather_agent = Agent(\n",
        "    name=\"weather_aware_planner\",\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    description=\"A trip planner that checks the real-time weather before making suggestions.\",\n",
        "    instruction=\"You are a cautious trip planner. Before suggesting any outdoor activities, you MUST use the `get_live_weather_forecast` tool to check conditions. Incorporate the live weather details into your recommendation.\",\n",
        "    tools=[get_live_weather_forecast]\n",
        ")\n",
        "\n",
        "print(f\"🌦️ Agent '{weather_agent.name}' is created and can now call a live weather API!\")\n",
        "\n",
        "# --- Let's test the Weather-Aware Planner ---\n",
        "await run_agent_query(weather_agent, \"I want to go hiking near Lake Tahoe tomorrow, what's the weather like?\")"
      ],
      "id": "custom_function_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Part 2: Specification-Driven Tools\n",
        "\n",
        "Instead of writing function by function, you can provide the agent with a formal specification, and it will generate the necessary tools automatically."
      ],
      "metadata": {
        "id": "part2_intro"
      },
      "id": "part2_intro"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 From an OpenAPI Spec (`OpenAPIToolset`)\n",
        "If you have an existing API with an OpenAPI specification, you can instantly turn it into a toolset for your agent. This is incredibly powerful for integrating with existing microservices."
      ],
      "metadata": {
        "id": "openapi_intro"
      },
      "id": "openapi_intro"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "openapi_code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "8268242f-eb6c-4ad9-875e-42aeb828f1a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Running query for agent: 'pet_store_agent'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "✅ Final Response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here is the pet with ID 5: doggie."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here is the pet with ID 5: doggie.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# A simple OpenAPI 3.0 spec for a Pet Store as a string\n",
        "pet_store_spec = \"\"\"\n",
        "openapi: 3.0.0\n",
        "info:\n",
        "  title: Simple Pet Store API\n",
        "  version: 1.0.0\n",
        "servers:\n",
        "  - url: https://petstore.swagger.io/v2\n",
        "paths:\n",
        "  /pet/{petId}:\n",
        "    get:\n",
        "      summary: Find pet by ID\n",
        "      operationId: getPetById\n",
        "      parameters:\n",
        "        - name: petId\n",
        "          in: path\n",
        "          required: true\n",
        "          schema:\n",
        "            type: integer\n",
        "            format: int64\n",
        "      responses:\n",
        "        '200':\n",
        "          description: successful operation\n",
        "          content:\n",
        "            application/json:\n",
        "              schema:\n",
        "                type: object\n",
        "                properties:\n",
        "                  id:\n",
        "                    type: integer\n",
        "                  name:\n",
        "                    type: string\n",
        "                  status:\n",
        "                    type: string\n",
        "\"\"\"\n",
        "\n",
        "# 1. Create the toolset from the OpenAPI spec string\n",
        "pet_store_toolset = OpenAPIToolset(\n",
        "    spec_str=pet_store_spec, spec_str_type='yaml'\n",
        ")\n",
        "\n",
        "# 2. Create an agent that uses this toolset\n",
        "pet_store_agent = Agent(\n",
        "    name=\"pet_store_agent\",\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    instruction=\"You are a Pet Store assistant. Use your tools to find information about pets.\",\n",
        "    tools=[pet_store_toolset]\n",
        ")\n",
        "\n",
        "# 3. Run the agent\n",
        "# The agent will see the `getPetById` tool and know how to call the API.\n",
        "await run_agent_query(pet_store_agent, \"Can you find the pet with ID 5?\")"
      ],
      "id": "openapi_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 From a Public Server (`MCPToolset`)\n",
        "**MCP** is a standard that lets agents discover tools from a remote server. We can use `MCPToolset` to connect to a public server hosting tools for the MDN Web Docs."
      ],
      "metadata": {
        "id": "mcp_intro"
      },
      "id": "mcp_intro"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mcp_code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d8f0ef5-d7f0-4aa4-b56d-b8adbdbc1e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Running query for agent: 'mdn_docs_assistant'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/google/adk/tools/mcp_tool/mcp_tool.py:87: UserWarning: [EXPERIMENTAL] BaseAuthenticatedTool: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
            "  super().__init__(\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_adk.google.adk.tools.base_authenticated_tool:auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "✅ Final Response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The CSS `box-sizing` property sets how the total width and height of an element is calculated.\n\nBy default, in the CSS box model, the `width` and `height` you assign to an element apply only to the element's content box. If the element has any border or padding, these are added to the specified `width` and `height` to determine the final rendered size of the box on the screen. This means you would need to adjust your `width` and `height` values to account for any border or padding.\n\nThe `box-sizing` property allows you to change this behavior with two main values:\n\n*   **`content-box`**: This is the initial and default value. The `width` and `height` properties include only the content area of the element. Padding and border are added *outside* this dimension.\n    *   For example, if you set `width: 100px; border: 10px solid black;`, the total rendered width of the box will be 100px (content) + 10px (left border) + 10px (right border) = 120px.\n\n*   **`border-box`**: This tells the browser to include any border and padding in the values you specify for an element's `width` and `height`. If you set an element's width to 100 pixels, that 100 pixels will encompass the content, padding, and border. The content area will shrink to accommodate the padding and border.\n    *   For example, if you set `width: 100px; border: 10px solid black;` with `box-sizing: border-box;`, the total rendered width will be 100px. The content area will be 100px - 10px (left border) - 10px (right border) = 80px.\n\nUsing `box-sizing: border-box` can simplify element sizing and layout, as it makes the declared width and height inclusive of padding and borders."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The CSS `box-sizing` property sets how the total width and height of an element is calculated.\\n\\nBy default, in the CSS box model, the `width` and `height` you assign to an element apply only to the element's content box. If the element has any border or padding, these are added to the specified `width` and `height` to determine the final rendered size of the box on the screen. This means you would need to adjust your `width` and `height` values to account for any border or padding.\\n\\nThe `box-sizing` property allows you to change this behavior with two main values:\\n\\n*   **`content-box`**: This is the initial and default value. The `width` and `height` properties include only the content area of the element. Padding and border are added *outside* this dimension.\\n    *   For example, if you set `width: 100px; border: 10px solid black;`, the total rendered width of the box will be 100px (content) + 10px (left border) + 10px (right border) = 120px.\\n\\n*   **`border-box`**: This tells the browser to include any border and padding in the values you specify for an element's `width` and `height`. If you set an element's width to 100 pixels, that 100 pixels will encompass the content, padding, and border. The content area will shrink to accommodate the padding and border.\\n    *   For example, if you set `width: 100px; border: 10px solid black;` with `box-sizing: border-box;`, the total rendered width will be 100px. The content area will be 100px - 10px (left border) - 10px (right border) = 80px.\\n\\nUsing `box-sizing: border-box` can simplify element sizing and layout, as it makes the declared width and height inclusive of padding and borders.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# The URL for the public server hosting MDN documentation tools\n",
        "MCP_SERVER_URL = \"https://gitmcp.io/mdn/content\"\n",
        "\n",
        "# This is an async function because MCPToolset needs to connect to the server\n",
        "async def create_mdn_agent():\n",
        "    mcp_toolset = MCPToolset(\n",
        "        connection_params=SseServerParams(url=MCP_SERVER_URL)\n",
        "    )\n",
        "    return Agent(\n",
        "        name=\"mdn_docs_assistant\",\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        tools=[mcp_toolset],\n",
        "        instruction=\"You are a web dev expert with access to MDN docs. Use your tools to answer questions.\"\n",
        "    )\n",
        "\n",
        "# Create and run the agent\n",
        "mdn_agent = await create_mdn_agent()\n",
        "await run_agent_query(mdn_agent, \"What is the CSS `box-sizing` property?\")"
      ],
      "id": "mcp_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Part 3: Interoperability\n",
        "\n",
        "You don't have to build everything from scratch. The ADK is designed to work with other popular AI frameworks."
      ],
      "metadata": {
        "id": "part3_intro"
      },
      "id": "part3_intro"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Using LangChain Tools (`LangchainTool`)\n",
        "If you have existing tools built with LangChain, you can wrap them using `LangchainTool` and use them directly in your ADK agent. Here, we'll wrap LangChain's `WikipediaAPIWrapper` tool."
      ],
      "metadata": {
        "id": "langchain_intro"
      },
      "id": "langchain_intro"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from google.adk.tools.langchain_tool import LangchainTool\n",
        "\n",
        "# 1. Instantiate the original LangChain tool\n",
        "# This tool queries the public Wikipedia API.\n",
        "wikipedia_tool = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "\n",
        "# 2. Wrap it for ADK using LangchainTool\n",
        "adk_wrapped_wiki_tool = LangchainTool(tool=wikipedia_tool)\n",
        "\n",
        "# 3. Use the wrapped tool in your ADK agent\n",
        "wiki_agent = Agent(\n",
        "    name=\"wiki_research_agent\",\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    instruction=\"You are a research assistant. Use the Wikipedia tool to answer the user's question.\",\n",
        "    tools=[adk_wrapped_wiki_tool]\n",
        ")\n",
        "\n",
        "# 4. Run the agent\n",
        "await run_agent_query(wiki_agent, \"What is the history of the Slinky toy?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "PIOQexQ_jrSK",
        "outputId": "b708e2b5-5e28-4cb2-a504-653e44f37322"
      },
      "id": "PIOQexQ_jrSK",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Running query for agent: 'wiki_research_agent'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "✅ Final Response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The Slinky toy was invented and developed by American naval engineer Richard T. James in 1943. It was successfully demonstrated at Gimbels department store in Philadelphia on November 27, 1945."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Slinky toy was invented and developed by American naval engineer Richard T. James in 1943. It was successfully demonstrated at Gimbels department store in Philadelphia on November 27, 1945.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Part 4: Advanced Composition\n",
        "\n",
        "Now let's combine these concepts to build more sophisticated systems."
      ],
      "metadata": {
        "id": "part4_intro"
      },
      "id": "part4_intro"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Sharing State Between Tools (`ToolContext`)\n",
        "What if one tool needs information gathered by another? `ToolContext` is a special object that can be passed to your tool functions, allowing them to read and write to a shared state dictionary within a single conversational turn."
      ],
      "metadata": {
        "id": "toolcontext_intro"
      },
      "id": "toolcontext_intro"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "toolcontext_code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "cffe878b-eb72-4c7c-94bd-d8ad6d3fc483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Running query for agent: 'stateful_agent'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🛠️ TOOL CALLED: Set preference 'theme' to 'dark mode'\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🛠️ TOOL CALLED: Retrieved preference 'theme', value is 'dark mode'\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "✅ Final Response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Your theme preference has been set to 'dark mode'."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Your theme preference has been set to 'dark mode'.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "def set_user_preference(preference: str, value: str, tool_context: ToolContext):\n",
        "    \"\"\"Saves a user's preference for this session.\n",
        "\n",
        "    Args:\n",
        "        preference: The name of the preference (e.g., 'theme').\n",
        "        value: The value of the preference (e.g., 'dark').\n",
        "    \"\"\"\n",
        "    # The state is a simple dictionary unique to this turn\n",
        "    tool_context.state[preference] = value\n",
        "    print(f\"\\n🛠️ TOOL CALLED: Set preference '{preference}' to '{value}'\\n\")\n",
        "    return {\"status\": \"success\", \"message\": f\"Preference saved.\"}\n",
        "\n",
        "def get_user_preference(preference: str, tool_context: ToolContext):\n",
        "    \"\"\"Gets a previously saved user preference.\n",
        "\n",
        "    Args:\n",
        "        preference: The name of the preference to retrieve.\n",
        "    \"\"\"\n",
        "    value = tool_context.state.get(preference, \"not set\")\n",
        "    print(f\"\\n🛠️ TOOL CALLED: Retrieved preference '{preference}', value is '{value}'\\n\")\n",
        "    return {\"preference\": preference, \"value\": value}\n",
        "\n",
        "\n",
        "stateful_agent = Agent(\n",
        "    name=\"stateful_agent\",\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    instruction=\"First, save the user's preference. Then, retrieve it and confirm it back to them.\",\n",
        "    tools=[set_user_preference, get_user_preference]\n",
        ")\n",
        "\n",
        "await run_agent_query(stateful_agent, \"Please set my theme preference to 'dark mode'.\")"
      ],
      "id": "toolcontext_code"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Agents as Tools (`AgentTool`)\n",
        "The ultimate composition pattern: using an entire agent as a tool for another agent. This lets you create a primary \"orchestrator\" that delegates complex tasks to a team of specialists.\n",
        "\n",
        "This example is the perfect demonstration of `ToolContext` in action. The orchestrator needs to perform a two-step process:\n",
        "1.  Call the `db_agent` to get a list of hotels.\n",
        "2.  Call the `concierge_agent` with the hotel data to get a recommendation.\n",
        "\n",
        "The `ToolContext` acts as a temporary \"clipboard\" or \"briefcase\" for the turn. The first tool (`call_db_agent`) places the hotel data into `tool_context.state`, and the second tool (`call_concierge_agent`) retrieves it.\n",
        "\n",
        "\n",
        "```\n",
        "                                 +-----------------------------------------------------------+\n",
        "                                 |                      🧭 TripDataConcierge                 |\n",
        "                                 |                        (Orchestrator)                     |\n",
        "                                 +-----------------------------------------------------------+\n",
        "                                            /                         \\\n",
        "                                           /                           \\\n",
        "               +----------------------------------+      +--------------------------------------+\n",
        "               | 🔧 Tool: call_db_agent           |      | 🔧 Tool: call_concierge_agent          |\n",
        "               | Writes data to `tool_context`    |      | Reads data from `tool_context`         |\n",
        "               | Calls: 📦 db_agent (for data)    |      | Calls: 🤵 concierge_agent (for advice) |\n",
        "               +----------------------------------+      +--------------------------------------+\n",
        "                                                                              |\n",
        "                                                                              ▼\n",
        "                                                           +------------------------------------+\n",
        "                                                           | 🤵 concierge_agent                 |\n",
        "                                                           | Tools: [ 🍽️ food_critic_agent ]    |\n",
        "                                                           +------------------------------------+\n",
        "                                                                              |\n",
        "                                                                              ▼\n",
        "                                                           +------------------------------------+\n",
        "                                                           | 🍽️ food_critic_agent               |\n",
        "                                                           | (Gives witty recommendations)      |\n",
        "                                                           +------------------------------------+\n",
        "```"
      ],
      "metadata": {
        "id": "agent_as_tool_intro"
      },
      "id": "agent_as_tool_intro"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "agent_as_tool_code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "1f5fa6e7-5786-4398-b4d7-34e0f887d0e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Orchestrator Agent 'trip_data_concierge' is defined and ready.\n",
            "\n",
            "🚀 Running query for agent: 'trip_data_concierge'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TOOL CALL: Delegating to db_agent ---\n",
            "--- CONTEXT: Writing to tool_context.state['retrieved_data']: ```json\n",
            "{\n",
            "  \"status\": \"success\",\n",
            "  \"data\": [\n",
            "    {... ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TOOL CALL: Delegating to concierge_agent ---\n",
            "--- CONTEXT: Reading from tool_context.state['retrieved_data']: ```json\n",
            "{\n",
            "  \"status\": \"success\",\n",
            "  \"data\": [\n",
            "    {... ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "✅ Final Response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The top-rated hotels in San Francisco are The Grand Hotel (5 stars, 450 reviews) and Seaside Inn (4 stars, 620 reviews). The Seaside Inn has the most reviews. For an exquisite dinner experience near the Seaside Inn, I would highly recommend **Quince**."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The top-rated hotels in San Francisco are The Grand Hotel (5 stars, 450 reviews) and Seaside Inn (4 stars, 620 reviews). The Seaside Inn has the most reviews. For an exquisite dinner experience near the Seaside Inn, I would highly recommend **Quince**.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# A mock database agent. In a real app, this might be a NL-to-SQL agent.\n",
        "db_agent = Agent(\n",
        "    name=\"db_agent\",\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    instruction=\"You are a database agent. When asked for data, return this mock JSON object: {'status': 'success', 'data': [{'name': 'The Grand Hotel', 'rating': 5, 'reviews': 450}, {'name': 'Seaside Inn', 'rating': 4, 'reviews': 620}]}\")\n",
        "\n",
        "# --- 1. Define the Specialist Agents ---\n",
        "\n",
        "# The Food Critic remains the deepest specialist\n",
        "food_critic_agent = Agent(\n",
        "    name=\"food_critic_agent\",\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    instruction=\"You are a snobby but brilliant food critic. You ONLY respond with a single, witty restaurant suggestion near the provided location.\",\n",
        ")\n",
        "\n",
        "# The Concierge knows how to use the Food Critic\n",
        "concierge_agent = Agent(\n",
        "    name=\"concierge_agent\",\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    instruction=\"You are a five-star hotel concierge. If the user asks for a restaurant recommendation, you MUST use the `food_critic_agent` tool. Present the opinion to the user politely.\",\n",
        "    tools=[AgentTool(agent=food_critic_agent)]\n",
        ")\n",
        "\n",
        "\n",
        "# --- 2. Define the Tools for the Orchestrator ---\n",
        "\n",
        "async def call_db_agent(question: str, tool_context: ToolContext):\n",
        "    \"\"\"\n",
        "    Use this tool FIRST to connect to the database and retrieve a list of places, like hotels or landmarks.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- TOOL CALL: Delegating to db_agent ---\")\n",
        "    agent_tool = AgentTool(agent=db_agent)\n",
        "    db_agent_output = await agent_tool.run_async(\n",
        "        args={\"request\": question}, tool_context=tool_context\n",
        "    )\n",
        "\n",
        "    # *** WRITING TO THE CONTEXT ***\n",
        "    # We store the data from the DB agent in the shared state.\n",
        "    print(f\"--- CONTEXT: Writing to tool_context.state['retrieved_data']: {db_agent_output[:50]}... ---\")\n",
        "    tool_context.state[\"retrieved_data\"] = db_agent_output\n",
        "\n",
        "    return db_agent_output\n",
        "\n",
        "\n",
        "async def call_concierge_agent(question: str, tool_context: ToolContext):\n",
        "    \"\"\"\n",
        "    After getting data with call_db_agent, use this tool to get travel advice, opinions, or recommendations.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- TOOL CALL: Delegating to concierge_agent ---\")\n",
        "\n",
        "    # *** READING FROM THE CONTEXT ***\n",
        "    # We retrieve the data that the previous tool call saved.\n",
        "    input_data = tool_context.state.get(\"retrieved_data\", \"No data found.\")\n",
        "    print(f\"--- CONTEXT: Reading from tool_context.state['retrieved_data']: {input_data[:50]}... ---\")\n",
        "\n",
        "\n",
        "    # Formulate a new prompt for the concierge, giving it the data context\n",
        "    question_with_data = f\"\"\"\n",
        "    Context: The database returned the following data: {input_data}\n",
        "\n",
        "    User's Request: {question}\n",
        "    \"\"\"\n",
        "\n",
        "    agent_tool = AgentTool(agent=concierge_agent)\n",
        "    concierge_output = await agent_tool.run_async(\n",
        "        args={\"request\": question_with_data}, tool_context=tool_context\n",
        "    )\n",
        "    return concierge_output\n",
        "\n",
        "\n",
        "# --- 3. Define the Top-Level Orchestrator Agent ---\n",
        "trip_data_concierge_agent = Agent(\n",
        "    name=\"trip_data_concierge\",\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    description=\"Top-level agent that queries a database for travel data, then calls a concierge agent for recommendations.\",\n",
        "    tools=[call_db_agent, call_concierge_agent],\n",
        "    instruction=\"\"\"\n",
        "    You are a master travel planner who uses data to make recommendations.\n",
        "\n",
        "    1.  **ALWAYS start with the `call_db_agent` tool** to fetch a list of places (like hotels) that match the user's criteria.\n",
        "\n",
        "    2.  After you have the data, **use the `call_concierge_agent` tool** to answer any follow-up questions for recommendations, opinions, or advice related to the data you just found.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "print(f\"✅ Orchestrator Agent '{trip_data_concierge_agent.name}' is defined and ready.\")\n",
        "\n",
        "\n",
        "# --- Run the Multi-Agent System ---\n",
        "await run_agent_query(\n",
        "    trip_data_concierge_agent,\n",
        "    \"Find the top-rated hotels in San Francisco, then suggest a dinner spot near the one with the most reviews.\"\n",
        ")"
      ],
      "id": "agent_as_tool_code"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OHFjoQVQCyzc"
      },
      "id": "OHFjoQVQCyzc",
      "execution_count": 23,
      "outputs": []
    }
  ]
}