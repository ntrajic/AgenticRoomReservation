{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ntrajic/AgenticRoomReservation/blob/main/ADK_Eval_Guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🤖 Building Your First AI Agent with the Google ADK\n",
        "\n",
        "Welcome! This notebook is your first step into the exciting world of **AI Agents**. An agent is more than just a chatbot; it's a smart program that uses a Large Language Model (LLM) like Gemini to **reason, plan, and use tools** to accomplish tasks.\n",
        "\n",
        "In this guide, we will build a simple \"Product Research Assistant\" agent. This agent will be able to answer questions about product details and prices by using specialized tools we provide it.\n",
        "\n",
        "We'll cover three key stages of professional agent development:\n",
        "1.  **💻 Implementation**: Defining the agent's logic and tools.\n",
        "2.  **🔧 Unit Testing**: Verifying that each tool works correctly in isolation.\n",
        "3.  **🧪 Evaluation**: Testing the entire agent to see if it can reason correctly and choose the right tool for a given query.\n",
        "\n",
        "Let's get started!"
      ],
      "metadata": {
        "id": "intro_cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Author\n",
        "\n",
        "Hi, I'm Qingyue (Annie) Wang, a Developer Advocate and AI Engineer at **Google**. I'm passionate about helping developers build amazing things with AI and cloud technologies.\n",
        "\n",
        "If you have questions about this notebook, feel free to reach out on [LinkedIn](https://www.linkedin.com/in/qingyuewang/) or [X (formerly Twitter)](https://twitter.com/qingyuewang).\n",
        "\n",
        "```\n",
        " (\\__/)\n",
        " (•ㅅ•)\n",
        " /づ  📚      Enjoy learning about AI Agents!\n",
        "```"
      ],
      "metadata": {
        "id": "K4u-qBTcxaDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 🎁 🛑 Important Prerequisite: Setup Your Environment! 🛑 🎁\n",
        "-----------------------------------------------------------------------------\n",
        "\n",
        "You will need a **Google AI API Key** to run this notebook.\n",
        "\n",
        "👉 **Get Your Key HERE**: [https://codelabs.developers.google.com/onramp/instructions#1](https://codelabs.developers.google.com/onramp/instructions#1)\n",
        "\n",
        "*Note: The LangChain integration in Part 4 requires an additional API key from a service like Tavily, which has a free tier.*\n",
        "\n",
        "-----------------------------------------------------------------------------\n",
        "```\n",
        " ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️  ⬆️\n",
        "   /\\_/\\     /\\_/\\     /\\_/\\      /\\_/\\      /\\_/\\\n",
        "  ( ^_^ )   ( -.- )   ( >_< )   ( =^.^= )   ( o_o )\n",
        "```"
      ],
      "metadata": {
        "id": "pM3HqQzFxecq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup: Installing Libraries\n",
        "\n",
        "First things first, we need to install the necessary Python libraries. We'll use the `pip` command to do this.\n",
        "\n",
        "* `google-adk`: This is the **Agent Development Kit (ADK)**. It provides the core building blocks for creating agents, like the `LlmAgent` and `FunctionTool` classes we'll use later.\n",
        "* `google-genai`: This library allows our Python code to communicate with the Google Gemini family of models, which will be the \"brain\" of our agent."
      ],
      "metadata": {
        "id": "install_explanation"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkXSpNgVSVeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4bf63e8-622c-4a62-f816-081d9c6230ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.1/218.1 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.7/335.7 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.9/155.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.5/229.5 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.8/103.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# @title 1. Install Libraries\n",
        "!pip install google-adk google-genai -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2. Configuration: Setting Your API Key\n",
        "\n",
        "To use Google's AI models, you need an API key. This key is like a password that proves to Google that you have permission to use its services. 🔑\n",
        "\n",
        "This code block does two things:\n",
        "1.  It uses `getpass` to create a secure input field for your API key. This prevents your key from being displayed on the screen or saved in the notebook's output.\n",
        "2.  It sets the API key as an **environment variable** (`os.environ`). This is a standard and secure practice that allows the Google libraries to automatically find and use the key without you having to paste it into your code directly.\n",
        "\n",
        "> **Get your API Key**: You can get a free API key from [Google AI for Developers](https://makersuite.google.com/app/apikey)."
      ],
      "metadata": {
        "id": "api_key_explanation"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Enter Your API Key\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "# Securely get the API key from the user\n",
        "print(\"🔑 Enter your Google AI API key to continue.\")\n",
        "google_api_key = getpass.getpass(\"   API key: \").strip()\n",
        "\n",
        "# Check if the key was provided and set it as an environment variable\n",
        "if not google_api_key:\n",
        "  raise ValueError(\"A Google AI API key is required to run this notebook.\")\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = google_api_key\n",
        "print(\"✅ API key configured.\")"
      ],
      "metadata": {
        "id": "p8AJhl-GSliY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92a1b4f-ed9b-4698-c39e-8051c1afba91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔑 Enter your Google AI API key to continue.\n",
            "   API key: ··········\n",
            "✅ API key configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3. Implementation: Defining the Agent and Its Tools\n",
        "\n",
        "This is the core of our project! We'll define the agent's capabilities here. The `%%writefile agent.py` command is a special \"magic\" command in notebooks that saves the content of this cell into a new file named `agent.py`. This helps keep our code organized.\n",
        "\n",
        "Let's break down what's inside `agent.py`:\n",
        "\n",
        "### Agent Tools 🛠️\n",
        "A **Tool** is a function that an agent can call to get information or perform an action. Here, we create two simple Python functions that act as our tools:\n",
        "- `get_product_details()`: Simulates looking up product information from a database.\n",
        "- `get_product_price()`: Simulates looking up a product's price.\n",
        "\n",
        "We then wrap these Python functions inside `FunctionTool(...)`. This ADK class inspects our function, understands its name and arguments (`product_name: str`), and makes it usable by the LLM.\n",
        "\n",
        "### The Agent's Brain 🧠\n",
        "The `LlmAgent` is the central component. We configure it with:\n",
        "- **`model`**: We specify `gemini-2.5-flash`, a fast and powerful model perfect for this kind of task.\n",
        "- **`tools`**: We give the agent the list of tools it's allowed to use.\n",
        "- **`instruction`**: This is the most critical part! The instruction (or \"system prompt\") is a set of rules and guidelines that tells the agent how to behave. It's how we steer the LLM's reasoning. We explicitly tell it **when** to use each tool based on keywords in the user's query."
      ],
      "metadata": {
        "id": "agent_definition_explanation"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Define the Agent and Tools (agent.py)\n",
        "%%writefile agent.py\n",
        "import textwrap\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.tools import FunctionTool\n",
        "\n",
        "# --- Tool Definitions ---\n",
        "# These are simple Python functions that our agent can call.\n",
        "# In a real application, these might connect to a database or a live API.\n",
        "\n",
        "def get_product_details(product_name: str) -> str:\n",
        "    \"\"\"Gathers basic details about a product.\"\"\"\n",
        "    details = {\n",
        "        \"smartphone\": \"A cutting-edge smartphone with advanced features.\",\n",
        "        \"laptop\": \"A high-performance laptop for work and play.\",\n",
        "        \"headphones\": \"Wireless headphones with noise cancellation.\",\n",
        "    }\n",
        "    return details.get(product_name.lower(), \"Product details not found.\")\n",
        "\n",
        "def get_product_price(product_name: str) -> str:\n",
        "    \"\"\"Gathers the price of a product.\"\"\"\n",
        "    prices = {\"smartphone\": \"$999\", \"laptop\": \"$1299\", \"headphones\": \"$199\"}\n",
        "    return prices.get(product_name.lower(), \"Product price not found.\")\n",
        "\n",
        "# --- Tool Objects ---\n",
        "# We wrap our functions in the `FunctionTool` class so the Agent can use them.\n",
        "get_product_details_tool = FunctionTool(get_product_details)\n",
        "get_product_price_tool = FunctionTool(get_product_price)\n",
        "\n",
        "# --- Agent Definition ---\n",
        "# These instructions are the agent's guide. It tells the LLM how to behave\n",
        "# and when to use the tools we've provided.\n",
        "AGENT_INSTRUCTIONS = textwrap.dedent(\"\"\"\n",
        "    You are a product research assistant.\n",
        "    - If the user asks for \"price\", \"cost\", or \"how much\", you MUST use the `get_product_price` tool.\n",
        "    - If the user asks for \"details\" or \"about\", you MUST use the `get_product_details` tool.\n",
        "    - If a query mentions both price and details, you MUST prioritize the `get_product_price` tool.\n",
        "    - Respond only with the direct output from the tool.\n",
        "\"\"\")\n",
        "\n",
        "# We create the agent, providing the model, instructions, and tools.\n",
        "root_agent = LlmAgent(\n",
        "    name=\"ProductAgent\",\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    instruction=AGENT_INSTRUCTIONS,\n",
        "    tools=[get_product_details_tool, get_product_price_tool],\n",
        ")"
      ],
      "metadata": {
        "id": "xEOmcJsISmOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e32b594c-d304-4510-daad-0aff6e3d6a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4. Unit Testing: Verifying Your Tools\n",
        "\n",
        "Before we test the whole agent, it's a best practice to test its individual components. This is called **Unit Testing**. If the tools don't work, the agent can't work!\n",
        "\n",
        "We use Python's built-in `unittest` framework to write a few simple checks:\n",
        "- We test that our functions return the correct data when a product is found (e.g., `get_product_price(\"smartphone\")` should be `\"$999\"`).\n",
        "- We test the \"unhappy path\": what happens when a product is *not* found (e.g., `get_product_price(\"toaster\")` should return the \"not found\" message).\n",
        "- We also check that the functions are case-insensitive, as we designed them to be.\n",
        "\n",
        "Seeing `OK` in the output means all our tool functions are behaving exactly as we expect. ✅"
      ],
      "metadata": {
        "id": "unit_test_explanation"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Run Unit Tests for Tools\n",
        "import unittest\n",
        "# We import the functions directly from the agent.py file we just created.\n",
        "from agent import get_product_price, get_product_details\n",
        "\n",
        "class TestProductTools(unittest.TestCase):\n",
        "    \"\"\"A test suite for the agent's individual tools.\"\"\"\n",
        "    def test_get_price_found(self):\n",
        "        self.assertEqual(get_product_price(\"smartphone\"), \"$999\")\n",
        "        self.assertEqual(get_product_price(\"LAPTOP\"), \"$1299\")\n",
        "\n",
        "    def test_get_price_not_found(self):\n",
        "        self.assertEqual(get_product_price(\"toaster\"), \"Product price not found.\")\n",
        "\n",
        "    def test_get_details_found(self):\n",
        "        self.assertEqual(get_product_details(\"headphones\"), \"Wireless headphones with noise cancellation.\")\n",
        "\n",
        "    def test_get_details_not_found(self):\n",
        "        self.assertEqual(get_product_details(\"watch\"), \"Product details not found.\")\n",
        "\n",
        "print(\"--- Running Tool Unit Tests ---\")\n",
        "# This command runs the tests defined in the class above.\n",
        "unittest.main(argv=['first-arg-is-ignored'], exit=False, verbosity=2)"
      ],
      "metadata": {
        "id": "KvA9OoSnVFYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddfb807c-08b1-4a67-edeb-7c9b15c26a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_get_details_found (__main__.TestProductTools.test_get_details_found) ... ok\n",
            "test_get_details_not_found (__main__.TestProductTools.test_get_details_not_found) ... ok\n",
            "test_get_price_found (__main__.TestProductTools.test_get_price_found) ... ok\n",
            "test_get_price_not_found (__main__.TestProductTools.test_get_price_not_found) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 4 tests in 0.006s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Tool Unit Tests ---\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7f7cbdff3090>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5. Evaluation: Creating Test Cases for the Agent\n",
        "\n",
        "Now for the exciting part: testing the agent's reasoning. While unit tests check if a function works, **evaluation** checks if the agent *chooses the right function* and produces the correct final answer.\n",
        "\n",
        "We create a JSON file (`evaluation.test.json`) to define our test cases. This is a standard format for agent evaluation. Each `eval_case` has:\n",
        "- **`user_content`**: The question we will ask the agent.\n",
        "- **`final_response`**: The *exact* answer we expect the agent to give.\n",
        "\n",
        "This file acts as our \"answer key.\" We'll use it in the next step to automatically grade our agent's performance."
      ],
      "metadata": {
        "id": "eval_json_explanation"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. Create Agent Evaluation Set (JSON)\n",
        "%%writefile evaluation.test.json\n",
        "{\n",
        "  \"eval_set_id\": \"product_agent_eval_set\",\n",
        "  \"eval_cases\": [\n",
        "    {\n",
        "      \"eval_id\": \"get_smartphone_price\",\n",
        "      \"conversation\": [\n",
        "        {\n",
        "          \"user_content\": { \"parts\": [{ \"text\": \"How much does the smartphone cost?\" }] },\n",
        "          \"final_response\": { \"parts\": [{ \"text\": \"$999\" }] }\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"eval_id\": \"get_laptop_details\",\n",
        "      \"conversation\": [\n",
        "        {\n",
        "          \"user_content\": { \"parts\": [{ \"text\": \"Tell me about the laptop\" }] },\n",
        "          \"final_response\": { \"parts\": [{ \"text\": \"A high-performance laptop for work and play.\" }] }\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"eval_id\": \"get_unknown_product_price\",\n",
        "      \"conversation\": [\n",
        "        {\n",
        "          \"user_content\": { \"parts\": [{ \"text\": \"What is the price of a toaster?\" }] },\n",
        "          \"final_response\": { \"parts\": [{ \"text\": \"Product price not found.\" }] }\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "_xjuWIzDSqno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8411581-6103-4ade-f127-8a2e5f579d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing evaluation.test.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6. Execution: Running the Evaluation\n",
        "\n",
        "This final code block brings everything together. It runs our evaluation by systematically comparing the agent's performance against the \"answer key\" we created in `evaluation.test.json`.\n",
        "\n",
        "Here’s the process:\n",
        "1.  **Load Data**: It opens and reads the `evaluation.test.json` file.\n",
        "2.  **Setup Runner**: It uses the `Runner` from the ADK, which is the engine for executing agent interactions.\n",
        "3.  **Loop Through Cases**: The code iterates through each test case from the JSON file.\n",
        "4.  **Run Query**: For each case, it sends the `user_content` (the query) to our agent.\n",
        "5.  **Compare Results**: It takes the agent's final text response (`actual`) and compares it directly to the `final_response` from our file (`expected`).\n",
        "6.  **Display Report**: Finally, it prints a clean report showing which tests `PASSED` and which `FAILED`.\n",
        "\n",
        "If all tests pass, congratulations! 🎉 You've successfully built, tested, and evaluated your first AI agent."
      ],
      "metadata": {
        "id": "eval_runner_explanation"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6. Run the Agent Evaluation\n",
        "import json\n",
        "import uuid\n",
        "from google.adk import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.genai.types import Content, Part\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Import the agent we defined in agent.py\n",
        "from agent import root_agent\n",
        "\n",
        "# --- Setup Dependencies ---\n",
        "# The evaluation framework needs a session service to manage conversations.\n",
        "# InMemorySessionService is a simple one for local testing.\n",
        "session_service = InMemorySessionService()\n",
        "my_user_id = f\"user-{uuid.uuid4()}\" # A unique ID for the user\n",
        "\n",
        "# --- Helper function to run a single query ---\n",
        "async def run_agent_query(agent, query: str, session, user_id: str):\n",
        "    runner = Runner(agent=agent, session_service=session_service, app_name=agent.name)\n",
        "    final_response = \"\"\n",
        "    try:\n",
        "        # Run the agent and wait for events\n",
        "        async for event in runner.run_async(\n",
        "            user_id=user_id,\n",
        "            session_id=session.id,\n",
        "            new_message=Content(parts=[Part(text=query)], role=\"user\")\n",
        "        ):\n",
        "            # We only care about the final text response for this test\n",
        "            if event.is_final_response():\n",
        "                final_response = event.content.parts[0].text\n",
        "    except Exception as e:\n",
        "        final_response = f\"An error occurred: {e}\"\n",
        "    return final_response\n",
        "\n",
        "# --- Main Evaluation Loop ---\n",
        "async def run_agent_evaluation(agent, eval_cases: list, user_id: str):\n",
        "    results = []\n",
        "    print(f\"--- 🧪 Starting Evaluation for Agent: {agent.name} ---\")\n",
        "    for case in eval_cases:\n",
        "        query = case[\"conversation\"][0][\"user_content\"][\"parts\"][0][\"text\"]\n",
        "        expected = case[\"conversation\"][0][\"final_response\"][\"parts\"][0][\"text\"]\n",
        "        eval_id = case[\"eval_id\"]\n",
        "\n",
        "        print(f\"\\nRunning Case: '{eval_id}'...\")\n",
        "        print(f\"Query: '{query}'\")\n",
        "\n",
        "        # Create a new session for each evaluation case to ensure they are independent\n",
        "        session = await session_service.create_session(app_name=agent.name, user_id=user_id)\n",
        "        actual = await run_agent_query(agent, query, session, user_id)\n",
        "\n",
        "        # The core of the evaluation: is the actual response what we expected?\n",
        "        passed = (expected.strip() == actual.strip())\n",
        "\n",
        "        results.append({\n",
        "            \"eval_id\": eval_id,\n",
        "            \"passed\": passed,\n",
        "            \"expected\": expected,\n",
        "            \"actual\": actual\n",
        "        })\n",
        "\n",
        "    print(\"\\n--- ✅ Evaluation Complete ---\")\n",
        "    return results\n",
        "\n",
        "# --- Execute the Evaluation ---\n",
        "with open(\"evaluation.test.json\") as f:\n",
        "    eval_data = json.load(f)\n",
        "\n",
        "results = await run_agent_evaluation(root_agent, eval_data[\"eval_cases\"], user_id=my_user_id)\n",
        "\n",
        "# --- Display the Results ---\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"          EVALUATION RESULTS\")\n",
        "print(\"=\"*40)\n",
        "for result in results:\n",
        "    status = \"✅ PASSED\" if result[\"passed\"] else \"❌ FAILED\"\n",
        "    print(f\"\\n🧪 Eval ID:  {result['eval_id']} ({status})\")\n",
        "    print(f\"  - Expected: {result['expected']}\")\n",
        "    print(f\"  - Actual:   {result['actual']}\")\n",
        "    print(\"—\" * 40)"
      ],
      "metadata": {
        "id": "NvjCgGuYSsgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1cd7208-a686-48a4-8994-42aa2cc5dfe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 🧪 Starting Evaluation for Agent: ProductAgent ---\n",
            "\n",
            "Running Case: 'get_smartphone_price'...\n",
            "Query: 'How much does the smartphone cost?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Case: 'get_laptop_details'...\n",
            "Query: 'Tell me about the laptop'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Case: 'get_unknown_product_price'...\n",
            "Query: 'What is the price of a toaster?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ✅ Evaluation Complete ---\n",
            "\n",
            "========================================\n",
            "          EVALUATION RESULTS\n",
            "========================================\n",
            "\n",
            "🧪 Eval ID:  get_smartphone_price (✅ PASSED)\n",
            "  - Expected: $999\n",
            "  - Actual:   $999\n",
            "\n",
            "————————————————————————————————————————\n",
            "\n",
            "🧪 Eval ID:  get_laptop_details (✅ PASSED)\n",
            "  - Expected: A high-performance laptop for work and play.\n",
            "  - Actual:   A high-performance laptop for work and play.\n",
            "\n",
            "————————————————————————————————————————\n",
            "\n",
            "🧪 Eval ID:  get_unknown_product_price (✅ PASSED)\n",
            "  - Expected: Product price not found.\n",
            "  - Actual:   Product price not found.\n",
            "\n",
            "————————————————————————————————————————\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 🎓 Next Steps & Further Learning\n",
        "\n",
        "Excellent work! You've learned the fundamentals of the agent development lifecycle. From here, you can explore more advanced topics:\n",
        "\n",
        "- **More Complex Tools**: Your tools could interact with real-world APIs, databases, or files.\n",
        "- **Chaining Agents**: You can have one agent (a \"manager\") that delegates tasks to other, more specialized agents.\n",
        "- **Advanced Evaluation**: Instead of exact-match, you can use an LLM to grade the agent's responses for quality and correctness.\n",
        "\n",
        "Check out these videos to continue your learning journey:\n",
        "\n",
        "* [Google AI Agent Development Kit (ADK) tutorial youtube](https://www.youtube.com/results?search_query=Google+AI+Agent+Development+Kit+tutorial)\n",
        "* [LLM Agents Explained youtube](https://www.youtube.com/results?search_query=LLM+Agents+Explained)"
      ],
      "metadata": {
        "id": "further_learning"
      }
    }
  ]
}